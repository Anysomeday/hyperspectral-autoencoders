

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Getting started with autoencoders &mdash; deephyp 0.1.5 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Getting started with classifiers" href="get_started_clf.html" />
    <link rel="prev" title="Getting Started" href="../get_started.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> deephyp
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../citing.html">How to cite</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../get_started.html">Getting Started</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Getting started with autoencoders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#download-a-hyperspectral-dataset">Download a hyperspectral dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-preparation">Data preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-iterator">Data iterator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#building-networks">Building networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#adding-training-operations">Adding training operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-networks">Training networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loading-and-testing-a-trained-network">Loading and testing a trained network</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="get_started_clf.html">Getting started with classifiers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Code Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../related_pubs.html">Related Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contact.html">Contact</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">deephyp</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../get_started.html">Getting Started</a> &raquo;</li>
        
      <li>Getting started with autoencoders</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/usage/get_started/get_started_ae.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="getting-started-with-autoencoders">
<h1>Getting started with autoencoders<a class="headerlink" href="#getting-started-with-autoencoders" title="Permalink to this headline">¶</a></h1>
<p>Autoencoders are unsupervised neural networks that are useful for a range of applications such as unsupervised feature learning and dimensionality reduction. Autoencoders are trained to learn the parameters for an <em>encoder</em> which maps the input data to a latent space and a <em>decoder</em> which reconstructs the input from the latent space. The latent space is often of a lower dimensionality then the input data, and can be thought of as a feature vector. The network is trained to minimise the reconstruction error between its decoded output and the input data (hence it is <em>unsupervised</em>). Once trained, the <em>encoder</em> can be used to map data to the latent space.</p>
<img alt="../../_images/cnn_latent_space.png" src="../../_images/cnn_latent_space.png" />
<div class="section" id="download-a-hyperspectral-dataset">
<h2>Download a hyperspectral dataset<a class="headerlink" href="#download-a-hyperspectral-dataset" title="Permalink to this headline">¶</a></h2>
<p>Some hyperspectral datasets in a matlab file format (.mat) can be downloaded from <a class="reference external" href="http://www.ehu.eus/ccwintco/index.php/Hyperspectral_Remote_Sensing_Scenes">here</a>. To get started, download the ‘Pavia University’ dataset.</p>
<p><strong>deephyp</strong> operates on hyperspectral data in numpy array format. The matlab file (.mat) you just downloaded can be read as a numpy array using the <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html">scipy.io.loadmat</a> function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.io</span>
<span class="n">mat</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">loadmat</span><span class="p">(</span> <span class="s1">&#39;PaviaU.mat&#39;</span> <span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">mat</span><span class="p">[</span> <span class="s1">&#39;paviaU&#39;</span> <span class="p">]</span>
</pre></div>
</div>
<p>where <em>img</em> is a numpy array. You are now ready to use the toolbox!</p>
</div>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>For both autoencoders and classifiers, the toolbox uses several key processes:</p>
<ul class="simple">
<li>data preparation</li>
<li>data iterator</li>
<li>building networks</li>
<li>adding train operations</li>
<li>training networks</li>
<li>loading and testing a trained network</li>
</ul>
<p>Each of these are elaborated on below:</p>
</div>
<div class="section" id="data-preparation">
<h2>Data preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">¶</a></h2>
<p>A class within the toolbox from the <em>data</em> module called <em>HypImg</em> handles the hyperspectral dataset and all of its meta-data. As mentioned earlier, the class accepts the hyperspectral data in numpy format, with shape [numRows x numCols x numBands] or [numSamples x numBands]. The networks in the toolbox operate in the spectral domain, not the spatial, so if a hypercube image is input with shape [numRows x numCols x numBands], it is reshaped to [numSamples x numBands], collapsing the spatial dimensions into a single dimension.</p>
<p>The Pavia Uni hyperspectral image can be passed to the <em>HypImg</em> class as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deephyp</span> <span class="kn">import</span> <span class="n">data</span>
<span class="n">hypData</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">HypImg</span><span class="p">(</span> <span class="n">img</span> <span class="p">)</span>
</pre></div>
</div>
<p>It is also possible to pass class labels to <em>HypImg</em>, but if you are training an unsupervised autoencoder you do not need to do this.</p>
<p>Then the data can be pre-processed using a function of the <em>HypImg</em> class. For example, using the ‘minmax’ approach:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hypData</span><span class="o">.</span><span class="n">pre_process</span><span class="p">(</span> <span class="s1">&#39;minmax&#39;</span> <span class="p">)</span>
</pre></div>
</div>
<p>The result is stored in the attribute <em>spectraPrep</em> attribute. Currently, only the ‘minmax’ approach is available, but additions will be made in future versions.</p>
</div>
<div class="section" id="data-iterator">
<h2>Data iterator<a class="headerlink" href="#data-iterator" title="Permalink to this headline">¶</a></h2>
<p>The <em>Iterator</em> class within the <em>data</em> module has methods for calling batches from the data that are used to train the network. A separate iterator object is made for the training and validation data. For example, an iterator object made from 200,000 pre-processed hyperspectral training samples with a batchsize of 1000 is defined by:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataTrain</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="p">(</span> <span class="n">dataSamples</span><span class="o">=</span><span class="n">hypData</span><span class="o">.</span><span class="n">spectraPrep</span><span class="p">[:</span><span class="mi">200000</span><span class="p">,</span> <span class="p">:],</span> <span class="n">targets</span><span class="o">=</span><span class="n">hypData</span><span class="o">.</span><span class="n">spectraPrep</span><span class="p">[:</span><span class="mi">200000</span><span class="p">,</span> <span class="p">:],</span> <span class="n">batchSize</span><span class="o">=</span><span class="mi">1000</span> <span class="p">)</span>
</pre></div>
</div>
<p>Similarly, an iterator object made from 100 validation samples is defined as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataVal</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="p">(</span> <span class="n">dataSamples</span><span class="o">=</span><span class="n">hypData</span><span class="o">.</span><span class="n">spectraPrep</span><span class="p">[</span><span class="mi">200000</span><span class="p">:</span><span class="mi">200100</span><span class="p">,</span> <span class="p">:],</span> <span class="n">targets</span><span class="o">=</span><span class="n">hypData</span><span class="o">.</span><span class="n">spectraPrep</span><span class="p">[</span><span class="mi">200000</span><span class="p">:</span><span class="mi">200100</span><span class="p">,</span> <span class="p">:]</span> <span class="p">)</span>
</pre></div>
</div>
<p>Because the batchsize is unspecified for the validation iterator, all 100 samples are used for each batch. For a typical unsupervised autoencoder, the targets that the network is learning to output are the same as the data samples being input into the network, as in the above iterator examples. When training a supervised classifier, the targets will be the ground truth class labels.</p>
<p>The data in any iterator can also be shuffled before it is used to train a network:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataTrain</span><span class="o">.</span><span class="n">shuffle</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="building-networks">
<h2>Building networks<a class="headerlink" href="#building-networks" title="Permalink to this headline">¶</a></h2>
<p>The <em>autoencoder</em> module has classes for creating autoencoder neural networks:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deephyp</span> <span class="kn">import</span> <span class="n">autoencoder</span>
</pre></div>
</div>
<p>There are currently two type of autoencoders that can be set up. A multi-layer perceptron (MLP) autoencoder has purely fully-connected (i.e. dense) layers:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">mlp_1D_network</span><span class="p">(</span> <span class="n">inputSize</span><span class="o">=</span><span class="n">hypData</span><span class="o">.</span><span class="n">numBands</span> <span class="p">)</span>
</pre></div>
</div>
<p>And a convolutional autoencoder has mostly convolutional layers, with a fully-connected layer used to map the final convolutional layer in the encoder to the latent vector:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">cnn_1D_network</span><span class="p">(</span> <span class="n">inputSize</span><span class="o">=</span><span class="n">hypData</span><span class="o">.</span><span class="n">numBands</span> <span class="p">)</span>
</pre></div>
</div>
<p>If not using config files to set up a network, then the input size of the data must be specified. This should be the number of spectral bands, which is stored in <em>hypData.numBands</em> for convenience.</p>
<p>Additional aspects of the network architecture can also be specified when initialising the <em>autoencoder</em> object. For the MLP autoencoder:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">mlp_1D_network</span><span class="p">(</span> <span class="n">inputSize</span><span class="o">=</span><span class="n">hypData</span><span class="o">.</span><span class="n">numBands</span><span class="p">,</span> <span class="n">encoderSize</span><span class="o">=</span><span class="p">[</span><span class="mi">50</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="n">activationFunc</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">weightInitOpt</span><span class="o">=</span><span class="s1">&#39;truncated_normal&#39;</span><span class="p">,</span> <span class="n">tiedWeights</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">skipConnect</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">activationFuncFinal</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>where the following components of the architecture can be specified:</p>
<ul class="simple">
<li>number of layers in the encoder (and decoder) - this is the length of the list ‘encoderSize’</li>
<li>number of neurons in each layer of the encoder - these are the values in the ‘encoderSize’ list. The last value in the list is the number of dimensions in the latent vector.</li>
<li>the activation function which proceeds each layer and the function for the final decoder layer - activationFunc and activationFuncFinal</li>
<li>the method of initialising network parameters (e.g. xavier improved) - ‘weightInitOpt’</li>
<li>which layers of the encoder to tie  to the decoder, such that they share a set of parameters - these are the values in the list ‘tiedWeights’</li>
<li>whether the network uses skip connections between corresponding layers in the encoder and decoder - specified by the boolean argument skipConnect</li>
</ul>
<p>Therefore, the above MLP autoencoder has four encoder layers (and four symmetric decoder layers), with five neurons in the latent layer. This network could be used to represent a hyperspectral image with five dimensions.</p>
<p>The convolutional autoencoder has similar arguments for defining the network architecture, but without ‘encoderSize’ and with some additional arguments:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">cnn_1D_network</span><span class="p">(</span> <span class="n">inputSize</span><span class="o">=</span><span class="n">hypData</span><span class="o">.</span><span class="n">numBands</span><span class="p">,</span> <span class="n">zDim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">encoderNumFilters</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="n">encoderFilterSize</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span>  <span class="n">activationFunc</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">weightInitOpt</span><span class="o">=</span><span class="s1">&#39;truncated_normal&#39;</span><span class="p">,</span>  <span class="n">encoderStride</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;VALID&#39;</span><span class="p">,</span> <span class="n">tiedWeights</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>  <span class="n">skipConnect</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">activationFuncFinal</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span> <span class="p">)</span>
</pre></div>
</div>
<p>which are:</p>
<ul class="simple">
<li>number of layers in the encoder (and decoder) - this is the length of the list ‘encodernumFilters’</li>
<li>number of filters/kernels in each conv layer - these are the values in the ‘encodernumFilters’ list</li>
<li>the size of the filters/kernels in each conv layer - these are the values in the ‘encoderFilterSize’ list</li>
<li>the stride of the filters/kernels in each conv layer - these are the values in the ‘encoderStride’ list</li>
<li>the number of dimensions in the latent vector - zDim</li>
<li>the type of padding each conv layer uses - padding</li>
</ul>
<p>Note that the convolutional autoencoder uses <em>deconvolutional</em> layers in the decoder, which can upsample the data from the latent layer to the output layer.</p>
<p>Instead of defining the network architecture by the initialisation arguments, a config.json file can be used:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">mlp_1D_network</span><span class="p">(</span> <span class="n">configFile</span><span class="o">=</span><span class="s1">&#39;config.json&#39;</span><span class="p">)</span> <span class="p">)</span>
</pre></div>
</div>
<p>A config file is generated each time a network in the toolbox is trained, so you can use one from another network as a template for making a new one.</p>
</div>
<div class="section" id="adding-training-operations">
<h2>Adding training operations<a class="headerlink" href="#adding-training-operations" title="Permalink to this headline">¶</a></h2>
<p>Once a network has been created, a training operation can be added to it. It is possible to add multiple training operations to a network, so each op must be given a name:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">add_train_op</span><span class="p">(</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;experiment_1&#39;</span> <span class="p">)</span>
</pre></div>
</div>
<p>When adding a train op, details about how the network will be trained with that op can also be specified. For example, a train op for an autoencoder which uses the cosine spectral angle (CSA) loss function, a learning rate of 0.001 with no decay, optimised with Adam and no weight decay can be defined by:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">add_train_op</span><span class="p">(</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;experiment_1&#39;</span><span class="p">,</span> <span class="n">lossFunc</span><span class="o">=</span><span class="s1">&#39;CSA&#39;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span> <span class="n">wd_lambda</span><span class="o">=</span><span class="mf">0.0</span> <span class="p">)</span>
</pre></div>
</div>
<p>There are several loss functions that can be used to train an autoencoder with this toolbox, many of which were designed specifically for hyperspectral data:</p>
<ul class="simple">
<li><a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/7533202">cosine spectral angle (CSA)</a></li>
<li><a class="reference external" href="https://www.mdpi.com/2072-4292/11/7/864">spectral angle (SA)</a></li>
<li><a class="reference external" href="https://www.mdpi.com/2072-4292/11/7/864">spectral information divergence (SID)</a></li>
<li><a class="reference external" href="https://www.mdpi.com/2072-4292/11/7/864">sum-of-squared errors (SSE)</a></li>
</ul>
<p>Note that when using the <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/7533202">CSA</a>, <a class="reference external" href="https://www.mdpi.com/2072-4292/11/7/864">SA</a> and <a class="reference external" href="https://www.mdpi.com/2072-4292/11/7/864">SID</a> loss functions it is expected that the reconstructed spectra have a different magnitude to the target spectra, but a similar shape. The <a class="reference external" href="https://www.mdpi.com/2072-4292/11/7/864">SSE</a> should produce a similar magnitude and shape. Also, since the SID contains <em>log</em> in its expression which is undefined for values <em>&lt;= 0</em>, it is best to use sigmoid as the activation function (including the final activation function) for networks trained with the SID loss. See the code examples for a demonstration.</p>
<p>The method for decaying the learning rate can also be customised. For example, to decay the learning rate exponentially every 100 steps (starting at 0.001):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">add_train_op</span><span class="p">(</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;experiment_1&#39;</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">decay_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">decay_rate</span><span class="o">=</span><span class="mf">0.9</span> <span class="p">)</span>
</pre></div>
</div>
<p>A piecewise approach to decaying the learning rate can also be used. For example, to change the learning rate from 0.001 to 0.0001 after 100 steps, and then to 0.00001 after a further 200 steps:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">add_train_op</span><span class="p">(</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;experiment_1&#39;</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">piecewise_bounds</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span><span class="mi">300</span><span class="p">],</span> <span class="n">piecewise_values</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span><span class="mf">1e-5</span><span class="p">]</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="training-networks">
<h2>Training networks<a class="headerlink" href="#training-networks" title="Permalink to this headline">¶</a></h2>
<p>Once one or multiple training ops have been added to a network, they can be used to learn a model (or multiple models) for that network through training:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">(</span> <span class="n">dataTrain</span><span class="o">=</span><span class="n">dataTrain</span><span class="p">,</span> <span class="n">dataVal</span><span class="o">=</span><span class="n">dataVal</span><span class="p">,</span> <span class="n">train_op_name</span><span class="o">=</span><span class="s1">&#39;experiment_1&#39;</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">save_addr</span><span class="o">=</span><span class="n">model_directory</span><span class="p">,</span> <span class="n">visualiseRateTrain</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">visualiseRateVal</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">save_epochs</span><span class="o">=</span><span class="p">[</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">])</span>
</pre></div>
</div>
<p>The train method learns a model using one train op, therefore the train method should be called at least once for each train op that was added. The name of the train op must be specified, and the training and validation iterators created previously must be input. A path to a directory to save the model must also be specified. The example above will train a network for 100 epochs of the training dataset (that is, loop through the entire training dataset 100 times), and save the model at 50 and 100 epochs. The training loss will be displayed every 5 epochs, and the validation loss will be displayed every 10 epochs.</p>
<p>It is also possible to load a pre-trained model and continue to train it by passing the address of the epoch folder containing the model checkpoint as the save_addr argument. For example, if the directory for the model at epoch 50 (epoch_50 folder) was passed to save_addr in the example above, then the model would initialise with the epoch 50 parameters and be trained for an additional 50 epochs to reach 100, at which point the model would be saved in a folder called epoch_100 in the same directory as the epoch_50 folder.</p>
<p>The interface for training autoencoders and classifiers is the same.</p>
</div>
<div class="section" id="loading-and-testing-a-trained-network">
<h2>Loading and testing a trained network<a class="headerlink" href="#loading-and-testing-a-trained-network" title="Permalink to this headline">¶</a></h2>
<p>Once you have a trained network, it can be loaded and tested out on some hyperspectral data.</p>
<p>Open a new python script. To load a trained model on a new dataset, ensure the data has been pre-processed similarly using:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deephyp</span> <span class="kn">import</span> <span class="n">data</span>
<span class="n">new_hypData</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">HypImg</span><span class="p">(</span> <span class="n">new_img</span> <span class="p">)</span>
<span class="n">new_hypData</span><span class="o">.</span><span class="n">pre_process</span><span class="p">(</span> <span class="s1">&#39;minmax&#39;</span> <span class="p">)</span>
</pre></div>
</div>
<p>Then set up the network. The network architecture must be the same as the one used to train the model being loaded. However, this is easy as the directory where models are saved should contain an automatically generated config.json file, which can be used to set up the network with the same architecture:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deephyp</span> <span class="kn">import</span> <span class="n">autoencoder</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">mlp_1D_network</span><span class="p">(</span> <span class="n">configFile</span><span class="o">=</span><span class="s1">&#39;model_directory/config.json&#39;</span> <span class="p">)</span>
</pre></div>
</div>
<p>Once the architecture has been defined, add a model to the network. For example, adding the model that was saved at epoch 100:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">add_model</span><span class="p">(</span> <span class="n">addr</span><span class="o">=</span><span class="s1">&#39;model_directory/epoch_100&#39;</span><span class="p">),</span> <span class="n">modelName</span><span class="o">=</span><span class="s1">&#39;csa_100&#39;</span> <span class="p">)</span>
</pre></div>
</div>
<p>Because multiple models can be added to a single network, the added model must be given a name. The name can be anything - the above model is named ‘csa_100’ because it was trained for 100 epochs using the cosine spectral angle loss function).</p>
<p>When the network is set up and a model has been added, hyperspectral data can be passed through it. To use a trained autoencoder to extract the latent vectors of some spectra:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataZ</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span> <span class="n">modelName</span><span class="o">=</span><span class="s1">&#39;csa_100&#39;</span><span class="p">,</span> <span class="n">dataSamples</span><span class="o">=</span><span class="n">new_hypData</span><span class="o">.</span><span class="n">spectraPrep</span> <span class="p">)</span>
</pre></div>
</div>
<p>Make sure to refer to the name of the model the network should use. The encoded hyperspectral data (<em>dataZ</em>) can also be decoded to get the reconstruction:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataY</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">modelName</span><span class="o">=</span><span class="s1">&#39;csa_100&#39;</span><span class="p">,</span> <span class="n">dataZ</span><span class="o">=</span><span class="n">dataZ</span><span class="p">)</span>
</pre></div>
</div>
<p>It is also possible to encode and decode in one step with:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataY</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">encoder_decoder</span><span class="p">(</span><span class="n">modelName</span><span class="o">=</span><span class="s1">&#39;csa_100&#39;</span><span class="p">,</span> <span class="n">dataZ</span><span class="o">=</span><span class="n">new_hypData</span><span class="o">.</span><span class="n">spectraPrep</span><span class="p">)</span>
</pre></div>
</div>
<p>You can use numpy to reshape the latent vector <em>dataZ</em> so that it looks like an image again:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">imgZ</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">dataZ</span><span class="p">,</span> <span class="p">(</span><span class="n">new_hypData</span><span class="o">.</span><span class="n">numRows</span><span class="p">,</span> <span class="n">new_hypData</span><span class="o">.</span><span class="n">numCols</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
</pre></div>
</div>
<p>Now you should have a basic idea of how to use the <strong>deephyp</strong> toolbox to train an autoencoder for hyperspectral data!</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="get_started_clf.html" class="btn btn-neutral float-right" title="Getting started with classifiers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../get_started.html" class="btn btn-neutral float-left" title="Getting Started" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Lloyd Windrim

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>