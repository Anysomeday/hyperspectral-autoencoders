

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>deephyp.autoencoder &mdash; deephyp 0.1.4 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> deephyp
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../usage/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/citing.html">How to cite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/api.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/examples.html">Code Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/related_pubs.html">Related Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/contact.html">Contact</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">deephyp</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>deephyp.autoencoder</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for deephyp.autoencoder</h1><div class="highlight"><pre>
<span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Description: high-level deep learning classes for building, training and using unsupervised autoencoders. Uses</span>
<span class="sd">    functions from the low-level network_ops module.</span>

<span class="sd">    - File name: autoencoder.py</span>
<span class="sd">    - Author: Lloyd Windrim</span>
<span class="sd">    - Date created: June 2019</span>
<span class="sd">    - Python package: deephyp</span>



<span class="sd">&#39;&#39;&#39;</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">deephyp</span> <span class="k">import</span> <span class="n">network_ops</span> <span class="k">as</span> <span class="n">net_ops</span>


<div class="viewcode-block" id="mlp_1D_network"><a class="viewcode-back" href="../../usage/mods/mod_ae_mlp.html#deephyp.autoencoder.mlp_1D_network">[docs]</a><span class="k">class</span> <span class="nc">mlp_1D_network</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot; Class for setting up a 1-D multi-layer perceptron (mlp) autoencoder network. Layers are all fully-connected \</span>
<span class="sd">        (i.e. dense).</span>

<span class="sd">    Args:</span>
<span class="sd">        configFile (str): Optional way of setting up the network. All other inputs can be ignored (will be overwritten). \</span>
<span class="sd">                        Pass the address of the .json config file.</span>
<span class="sd">        inputSize (int): Number of dimensions of input data (i.e. number of spectral bands). Value must be input if \</span>
<span class="sd">                        not using a config file.</span>
<span class="sd">        encoderSize (int list): Number of nodes at each layer of the encoder. List length is number of encoder layers.</span>
<span class="sd">        activationFunc (str): Activation function for all layers except the last one. Current options: [&#39;sigmoid&#39;, \</span>
<span class="sd">                        &#39;relu&#39;, &#39;linear&#39;].</span>
<span class="sd">        tiedWeights (binary list or None): Specifies whether or not to tie weights at each layer:</span>
<span class="sd">                        - 1: tied weights of specific encoder layer to corresponding decoder weights</span>
<span class="sd">                        - 0: do not tie weights of specific layer</span>
<span class="sd">                        - None: sets all layers to 0</span>
<span class="sd">        weightInitOpt (string): Method of weight initialisation. Current options: [&#39;gaussian&#39;, &#39;truncated_normal&#39;, \</span>
<span class="sd">                        &#39;xavier&#39;, &#39;xavier_improved&#39;].</span>
<span class="sd">        weightStd (float): Used by &#39;gaussian&#39; and &#39;truncated_normal&#39; weight initialisation methods.</span>
<span class="sd">        skipConnect (boolean): Whether to use skip connections throughout the network.</span>
<span class="sd">        activationFuncFinal (str): Activation function for final layer. Current options: [&#39;sigmoid&#39;, &#39;relu&#39;, &#39;linear&#39;].</span>

<span class="sd">    Attributes:</span>
<span class="sd">        inputSize (int): Number of dimensions of input data (i.e. number of spectral bands).</span>
<span class="sd">        activationFunc (str): Activation function for all layers except the last one.</span>
<span class="sd">        tiedWeights (binary list): Whether (1) or not (0) the weights of an encoder layer are tied to a decoder layer.</span>
<span class="sd">        skipConnect (boolean): Whether the network uses skip connections between corresponding encoder and decoder layers.</span>
<span class="sd">        weightInitOpt (string): Method of weight initialisation.</span>
<span class="sd">        weightStd (float): Parameter for &#39;gaussian&#39; and &#39;truncated_normal&#39; weight initialisation methods.</span>
<span class="sd">        activationFuncFinal (str): Activation function for final layer.</span>
<span class="sd">        encoderSize (int list): Number of inputs and number of nodes at each layer of the encoder.</span>
<span class="sd">        decoderSize (int list): Number of nodes at each layer of the decoder and number of outputs.</span>
<span class="sd">        z (tensor): Latent representation of data. Accessible through the *encoder* class function, requiring a trained \</span>
<span class="sd">            model.</span>
<span class="sd">        y_recon (tensor): Reconstructed output of network. Accessible through the *decoder* and *encoder_decoder* class \</span>
<span class="sd">            functions, requiring a trained model.</span>
<span class="sd">        train_ops (dict): Dictionary of names of train and loss ops (suffixed with _train and _loss) added to the \</span>
<span class="sd">            network using the *add_train_op* class function. The name (without suffix) is passed to the *train* class \</span>
<span class="sd">            function to train the network with the referenced train and loss op.</span>
<span class="sd">        modelsAddrs (dict): Dictionary of model names added to the network using the *add_model* class function. The \</span>
<span class="sd">            names reference models which can be used by the *encoder*, *decoder* and *encoder_decoder* class functions.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span> <span class="bp">self</span> <span class="p">,</span> <span class="n">configFile</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputSize</span><span class="o">=</span><span class="kc">None</span> <span class="p">,</span> <span class="n">encoderSize</span><span class="o">=</span><span class="p">[</span><span class="mi">50</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">10</span><span class="p">]</span> <span class="p">,</span> <span class="n">activationFunc</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span> <span class="p">,</span>
                  <span class="n">tiedWeights</span><span class="o">=</span><span class="kc">None</span> <span class="p">,</span> <span class="n">weightInitOpt</span><span class="o">=</span><span class="s1">&#39;truncated_normal&#39;</span> <span class="p">,</span> <span class="n">weightStd</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">skipConnect</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">activationFuncFinal</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span>  <span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">inputSize</span> <span class="o">=</span> <span class="n">inputSize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activationFunc</span> <span class="o">=</span> <span class="n">activationFunc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tiedWeights</span> <span class="o">=</span> <span class="n">tiedWeights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">skipConnect</span> <span class="o">=</span> <span class="n">skipConnect</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span> <span class="o">=</span> <span class="n">weightInitOpt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weightStd</span> <span class="o">=</span> <span class="n">weightStd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encodersize</span> <span class="o">=</span> <span class="n">encoderSize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activationFuncFinal</span> <span class="o">=</span> <span class="n">activationFuncFinal</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">net_config</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;inputSize&#39;</span><span class="p">,</span><span class="s1">&#39;encodersize&#39;</span><span class="p">,</span><span class="s1">&#39;activationFunc&#39;</span><span class="p">,</span><span class="s1">&#39;tiedWeights&#39;</span><span class="p">,</span><span class="s1">&#39;weightInitOpt&#39;</span><span class="p">,</span><span class="s1">&#39;weightStd&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;skipConnect&#39;</span><span class="p">,</span><span class="s1">&#39;activationFuncFinal&#39;</span><span class="p">]</span>
        <span class="c1"># loading config file overwrites input arguments</span>
        <span class="k">if</span> <span class="n">configFile</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">net_ops</span><span class="o">.</span><span class="n">load_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">configFile</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputSize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;value must be given for inputSize (not None)&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inputSize</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">encodersize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoderSize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputSize</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_target</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputSize</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">{</span> <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">{</span> <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_ops</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modelsAddrs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tiedWeights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tiedWeights</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># encoder weights</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span> <span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encoder_w</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> \
                <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span><span class="p">[</span><span class="n">layerNum</span><span class="p">],</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span><span class="p">[</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">]],</span><span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># decoder weights</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderSize</span> <span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tiedWeights</span><span class="p">[</span><span class="n">layerNum</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decoder_w</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span> <span class="p">)</span> <span class="o">+</span> <span class="n">layerNum</span> <span class="p">)]</span> <span class="o">=</span> \
                    <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">decoderSize</span><span class="p">[</span><span class="n">layerNum</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderSize</span><span class="p">[</span><span class="n">layerNum</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]],</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">tiedWeights</span><span class="p">[</span><span class="n">layerNum</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decoder_w</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span><span class="p">)</span> <span class="o">+</span> <span class="n">layerNum</span><span class="p">)]</span> <span class="o">=</span> \
                    <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encoder_w</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="n">layerNum</span><span class="p">)]</span> <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;unknown tiedWeights value: </span><span class="si">%i</span><span class="s1">. &#39;</span>
                                 <span class="s1">&#39;Must be 0 or 1 for each layer (or None).&#39;</span> <span class="o">%</span> <span class="n">tiedWeights</span><span class="p">[</span><span class="n">layerNum</span><span class="p">])</span>



        <span class="c1"># encoder biases</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span> <span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;encoder_b</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> \
                <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span><span class="p">[</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span> <span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># decoder biases</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderSize</span> <span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;decoder_b</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span> <span class="p">)</span> <span class="o">+</span> <span class="n">layerNum</span> <span class="p">)]</span> <span class="o">=</span> \
                <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">decoderSize</span><span class="p">[</span><span class="n">layerNum</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># build network using encoder, decoder and x placeholder as input</span>

        <span class="c1"># build encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="mi">1</span> <span class="p">,</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span> <span class="p">)</span> <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="p">)]</span> <span class="o">=</span> \
                <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_fullyConn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encoder_w</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="p">)],</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;encoder_b</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="p">)])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="p">)]</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">activationFunc</span><span class="p">)</span>

        <span class="c1"># latent representation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="p">)]</span>

        <span class="c1"># build decoder</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="mi">1</span> <span class="p">,</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderSize</span> <span class="p">)</span> <span class="p">):</span>
            <span class="n">absLayerNum</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderSize</span><span class="p">)</span> <span class="o">+</span> <span class="n">layerNum</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span> <span class="o">=</span> \
                <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_fullyConn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">absLayerNum</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decoder_w</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">absLayerNum</span><span class="p">)],</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;decoder_b</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">absLayerNum</span><span class="p">)])</span>
            <span class="k">if</span> <span class="n">layerNum</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderSize</span> <span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">skipConnect</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoderSize</span><span class="p">)</span> <span class="o">-</span> <span class="n">layerNum</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span> <span class="o">=</span> \
                    <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">activationFunc</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">skipConnect</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a0&#39;</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span> <span class="o">=</span> \
                    <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">activationFuncFinal</span><span class="p">)</span>

        <span class="c1"># output of final layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span>



<div class="viewcode-block" id="mlp_1D_network.add_train_op"><a class="viewcode-back" href="../../usage/mods/mod_ae_mlp.html#deephyp.autoencoder.mlp_1D_network.add_train_op">[docs]</a>    <span class="k">def</span> <span class="nf">add_train_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="p">,</span><span class="n">lossFunc</span><span class="o">=</span><span class="s1">&#39;CSA&#39;</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">decay_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decay_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">piecewise_bounds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">piecewise_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span> <span class="n">wd_lambda</span><span class="o">=</span><span class="mf">0.0</span> <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Constructs a loss op and training op from a specific loss function and optimiser. User gives the ops a \</span>
<span class="sd">            name, and the train op and loss opp are stored in a dictionary (train_ops) under that name.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): Name of the training op (to refer to it later in-case of multiple training ops).</span>
<span class="sd">            lossFunc (str): Reconstruction loss function.</span>
<span class="sd">            learning_rate (float): Controls the degree to which the weights are updated during training.</span>
<span class="sd">            decay_steps (int): Epoch frequency at which to decay the learning rate.</span>
<span class="sd">            decay_rate (float): Fraction at which to decay the learning rate.</span>
<span class="sd">            piecewise_bounds (int list): Epoch step intervals for decaying the learning rate. Alternative to decay steps.</span>
<span class="sd">            piecewise_values (float list): Rate at which to decay the learning rate at the piecewise_bounds.</span>
<span class="sd">            method (str): Optimisation method.</span>
<span class="sd">            wd_lambda (float): Scalar to control weighting of weight decay in loss.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># construct loss op</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_ops</span><span class="p">[</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_loss&#39;</span><span class="o">%</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">loss_function_reconstruction_1D</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_recon</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_target</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span><span class="n">lossFunc</span><span class="p">)</span>

        <span class="c1"># weight decay loss contribution</span>
        <span class="n">wdLoss</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">loss_weight_decay</span><span class="p">(</span><span class="n">wd_lambda</span><span class="p">)</span>

        <span class="c1"># construct training op</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_ops</span><span class="p">[</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_train&#39;</span><span class="o">%</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">net_ops</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_ops</span><span class="p">[</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_loss&#39;</span><span class="o">%</span><span class="n">name</span><span class="p">]</span><span class="o">+</span><span class="n">wdLoss</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">decay_steps</span><span class="p">,</span> <span class="n">decay_rate</span><span class="p">,</span>
                               <span class="n">piecewise_bounds</span><span class="p">,</span> <span class="n">piecewise_values</span><span class="p">,</span><span class="n">method</span><span class="p">)</span></div>




<div class="viewcode-block" id="mlp_1D_network.train"><a class="viewcode-back" href="../../usage/mods/mod_ae_mlp.html#deephyp.autoencoder.mlp_1D_network.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataTrain</span><span class="p">,</span> <span class="n">dataVal</span><span class="p">,</span> <span class="n">train_op_name</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">save_addr</span><span class="p">,</span> <span class="n">visualiseRateTrain</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">visualiseRateVal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
              <span class="n">save_epochs</span><span class="o">=</span><span class="p">[</span><span class="mi">1000</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot; Calls network_ops function to train a network.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataTrain (obj): Iterator object for training data.</span>
<span class="sd">            dataVal (obj): Iterator object for validation data.</span>
<span class="sd">            train_op_name (str): Name of training op created.</span>
<span class="sd">            n_epochs (int): Number of loops through dataset to train for.</span>
<span class="sd">            save_addr (str): Address of a directory to save checkpoints for desired epochs, or address of saved \</span>
<span class="sd">                        checkpoint. If address is for an epoch and contains a previously saved checkpoint, then the \</span>
<span class="sd">                        network will start training from there. Otherwise it will be trained from scratch.</span>
<span class="sd">            visualiseRateTrain (int): Epoch rate at which to print training loss in console.</span>
<span class="sd">            visualiseRateVal (int): Epoch rate at which to print validation loss in console.</span>
<span class="sd">            save_epochs (int list): Epochs to save checkpoints at.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># make sure a checkpoint is saved at n_epochs</span>
        <span class="k">if</span> <span class="n">n_epochs</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">save_epochs</span><span class="p">:</span>
            <span class="n">save_epochs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>

        <span class="n">net_ops</span><span class="o">.</span><span class="n">train</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dataTrain</span><span class="p">,</span> <span class="n">dataVal</span><span class="p">,</span> <span class="n">train_op_name</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">save_addr</span><span class="p">,</span> <span class="n">visualiseRateTrain</span><span class="p">,</span>
                       <span class="n">visualiseRateVal</span><span class="p">,</span> <span class="n">save_epochs</span> <span class="p">)</span></div>


<div class="viewcode-block" id="mlp_1D_network.add_model"><a class="viewcode-back" href="../../usage/mods/mod_ae_mlp.html#deephyp.autoencoder.mlp_1D_network.add_model">[docs]</a>    <span class="k">def</span> <span class="nf">add_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">addr</span><span class="p">,</span><span class="n">modelName</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Loads a saved set of model parameters for the network.</span>

<span class="sd">        Args:</span>
<span class="sd">            addr (str): Address of the directory containing the checkpoint files.</span>
<span class="sd">            modelName (str): Name of the model (to refer to it later in-case of multiple models for a given network).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">modelsAddrs</span><span class="p">[</span><span class="n">modelName</span><span class="p">]</span> <span class="o">=</span> <span class="n">addr</span></div>

<div class="viewcode-block" id="mlp_1D_network.encoder"><a class="viewcode-back" href="../../usage/mods/mod_ae_mlp.html#deephyp.autoencoder.mlp_1D_network.encoder">[docs]</a>    <span class="k">def</span> <span class="nf">encoder</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">modelName</span><span class="p">,</span> <span class="n">dataSamples</span>  <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Extract the latent variable of some dataSamples using a trained model.</span>

<span class="sd">        Args:</span>
<span class="sd">            modelName (str): Name of the model to use (previously added with add_model() ).</span>
<span class="sd">            dataSample (np.array): Shape [numSamples x inputSize].</span>

<span class="sd">        Returns:</span>
<span class="sd">            (np.array): Latent representation z of dataSamples. Shape [numSamples x arbitrary].</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

            <span class="c1"># load the model</span>
            <span class="n">net_ops</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modelsAddrs</span><span class="p">[</span><span class="n">modelName</span><span class="p">],</span> <span class="n">sess</span><span class="p">)</span>

            <span class="c1"># get latent values</span>
            <span class="n">dataZ</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">:</span> <span class="n">dataSamples</span><span class="p">})</span>

            <span class="k">return</span> <span class="n">dataZ</span></div>



<div class="viewcode-block" id="mlp_1D_network.decoder"><a class="viewcode-back" href="../../usage/mods/mod_ae_mlp.html#deephyp.autoencoder.mlp_1D_network.decoder">[docs]</a>    <span class="k">def</span> <span class="nf">decoder</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">modelName</span><span class="p">,</span> <span class="n">dataZ</span>  <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Extract the reconstruction of some dataSamples from their latent representation encoding  using a trained \</span>
<span class="sd">            model.</span>

<span class="sd">        Args:</span>
<span class="sd">            modelName (str): Name of the model to use (previously added with add_model() ).</span>
<span class="sd">            dataZ (np.array): Latent representation of data samples to reconstruct using the network. Shape \</span>
<span class="sd">                    [numSamples x arbitrary].</span>

<span class="sd">        Returns:</span>
<span class="sd">            (np.array): Reconstructed data (y_recon attribute). Shape [numSamples x arbitrary].</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

            <span class="c1"># load the model</span>
            <span class="n">net_ops</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modelsAddrs</span><span class="p">[</span><span class="n">modelName</span><span class="p">],</span> <span class="n">sess</span><span class="p">)</span>

            <span class="c1"># get reconstruction</span>
            <span class="n">dataY_recon</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_recon</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">:</span> <span class="n">dataZ</span><span class="p">})</span>

            <span class="k">return</span> <span class="n">dataY_recon</span></div>


<div class="viewcode-block" id="mlp_1D_network.encoder_decoder"><a class="viewcode-back" href="../../usage/mods/mod_ae_mlp.html#deephyp.autoencoder.mlp_1D_network.encoder_decoder">[docs]</a>    <span class="k">def</span> <span class="nf">encoder_decoder</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">modelName</span><span class="p">,</span> <span class="n">dataSamples</span>  <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Extract the reconstruction of some dataSamples using a trained model.</span>

<span class="sd">        Args:</span>
<span class="sd">            modelName (str): Name of the model to use (previously added with add_model() ).</span>
<span class="sd">            dataSample (np.array): Data samples to reconstruct using the network. Shape [numSamples x inputSize].</span>

<span class="sd">        Returns:</span>
<span class="sd">            (np.array): Reconstructed data (y_recon attribute). Shape [numSamples x arbitrary].</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

            <span class="c1"># load the model</span>
            <span class="n">net_ops</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modelsAddrs</span><span class="p">[</span><span class="n">modelName</span><span class="p">],</span> <span class="n">sess</span><span class="p">)</span>

            <span class="c1"># get reconstruction</span>
            <span class="n">dataY_recon</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_recon</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">:</span> <span class="n">dataSamples</span><span class="p">})</span>

            <span class="k">return</span> <span class="n">dataY_recon</span></div></div>





<div class="viewcode-block" id="cnn_1D_network"><a class="viewcode-back" href="../../usage/mods/mod_ae_cnn.html#deephyp.autoencoder.cnn_1D_network">[docs]</a><span class="k">class</span> <span class="nc">cnn_1D_network</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot; Class for setting up a 1-D convolutional autoencoder network. Builds a network with an encoder containing  \</span>
<span class="sd">        convolutional layers followed by a single fully-connected layer to map from the final convolutional layer in \</span>
<span class="sd">        the encoder to the latent layer. The decoder contains a single fully-connected layer and then several \</span>
<span class="sd">        deconvolutional layers which reconstruct the spectra in the output.</span>


<span class="sd">    Args:</span>
<span class="sd">        configFile (str): Optional way of setting up the network. All other inputs can be ignored (will be overwritten). \</span>
<span class="sd">                        Pass the address of the .json config file.</span>
<span class="sd">        inputSize (int): Number of dimensions of input data (i.e. number of spectral bands). Value must be input if not \</span>
<span class="sd">                        using a config file.</span>
<span class="sd">        zDim (int): Dimensionality of latent vector.</span>
<span class="sd">        encoderNumFilters (int list): Number of filters at each layer of the encoder. List length is number of \</span>
<span class="sd">                        convolutional encoder layers. Note that there is a single mlp layer after the last \</span>
<span class="sd">                        convolutional layer.</span>
<span class="sd">        encoderFilterSize (int list): Size of filter at each layer of the encoder. List length is number of encoder layers.</span>
<span class="sd">        activationFunc (str): Activation function for all layers except the last one. Current options: [&#39;sigmoid&#39;, \</span>
<span class="sd">                        &#39;relu&#39;, &#39;linear&#39;].</span>
<span class="sd">        tiedWeights (binary list or None): Specifies whether or not to tie weights at each layer:</span>
<span class="sd">                    - 1: tied weights of specific encoder layer to corresponding decoder weights</span>
<span class="sd">                    - 0: do not tie weights of specific layer</span>
<span class="sd">                    - None: sets all layers to 0</span>
<span class="sd">        weightInitOpt (string): Method of weight initialisation. Current options: [&#39;gaussian&#39;, &#39;truncated_normal&#39;, \</span>
<span class="sd">                    &#39;xavier&#39;, &#39;xavier_improved&#39;].</span>
<span class="sd">        weightStd (float): Used by &#39;gaussian&#39; and &#39;truncated_normal&#39; weight initialisation methods.</span>
<span class="sd">        skipConnect (boolean): Whether to use skip connections throughout the network.</span>
<span class="sd">        padding (str): Type of padding used. Current options: [&#39;VALID&#39;, &#39;SAME&#39;].</span>
<span class="sd">        encoderStride (int list): Stride at each convolutional encoder layer.</span>
<span class="sd">        activationFuncFinal (str): Activation function for final layer. Current options: [&#39;sigmoid&#39;, &#39;relu&#39;, &#39;linear&#39;].</span>


<span class="sd">    Attributes:</span>
<span class="sd">        inputSize (int): Number of dimensions of input data (i.e. number of spectral bands).</span>
<span class="sd">        activationFunc (str): Activation function for all layers except the last one.</span>
<span class="sd">        tiedWeights (binary list): Whether (1) or not (0) the weights of an encoder layer are tied to a decoder layer.</span>
<span class="sd">        skipConnect (boolean): Whether the network uses skip connections between corresponding encoder and decoder layers.</span>
<span class="sd">        weightInitOpt (string): Method of weight initialisation.</span>
<span class="sd">        weightStd (float): Parameter for &#39;gaussian&#39; and &#39;truncated_normal&#39; weight initialisation methods.</span>
<span class="sd">        activationFuncFinal (str): Activation function for final layer.</span>
<span class="sd">        encoderNumFilters (int list): Number of filters at each layer of the encoder. List length is number of \</span>
<span class="sd">                        convolutional encoder layers. Note that there is a single mlp layer after the last \</span>
<span class="sd">                        convolutional layer.</span>
<span class="sd">        encoderFilterSize (int list): Size of filter at each layer of the encoder. List length is number of encoder layers.</span>
<span class="sd">        encoderStride (int list): Stride at each convolutional encoder layer.</span>
<span class="sd">        decoderNumFilters (int list):</span>
<span class="sd">        decoderFilterSize (int list):</span>
<span class="sd">        decoderStride (int list):</span>
<span class="sd">        zDim (int): Dimensionality of latent vector.</span>
<span class="sd">        padding (str): Type of padding used. Current options: [&#39;VALID&#39;, &#39;SAME&#39;].</span>
<span class="sd">        z (tensor): Latent representation of data. Accessible through the *encoder* class function, requiring a trained \</span>
<span class="sd">            model.</span>
<span class="sd">        y_recon (tensor): Reconstructed output of network. Accessible through the *decoder* and *encoder_decoder* class \</span>
<span class="sd">            functions, requiring a trained model.</span>
<span class="sd">        train_ops (dict): Dictionary of names of train and loss ops (suffixed with _train and _loss) added to the \</span>
<span class="sd">            network using the *add_train_op* class function. The name (without suffix) is passed to the *train* class \</span>
<span class="sd">            function to train the network with the referenced train and loss op.</span>
<span class="sd">        modelsAddrs (dict): Dictionary of model names added to the network using the *add_model* class function. The \</span>
<span class="sd">            names reference models which can be used by the *encoder*, *decoder* and *encoder_decoder* class functions.</span>



<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span> <span class="bp">self</span> <span class="p">,</span> <span class="n">configFile</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputSize</span><span class="o">=</span><span class="kc">None</span> <span class="p">,</span> <span class="n">zDim</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">encoderNumFilters</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">]</span> <span class="p">,</span>
                  <span class="n">encoderFilterSize</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="n">activationFunc</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">tiedWeights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">weightInitOpt</span><span class="o">=</span><span class="s1">&#39;truncated_normal&#39;</span><span class="p">,</span> <span class="n">weightStd</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">skipConnect</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;VALID&#39;</span><span class="p">,</span>
                  <span class="n">encoderStride</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">activationFuncFinal</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span> <span class="p">):</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">inputSize</span> <span class="o">=</span> <span class="n">inputSize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tiedWeights</span> <span class="o">=</span> <span class="n">tiedWeights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">skipConnect</span> <span class="o">=</span> <span class="n">skipConnect</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span> <span class="o">=</span> <span class="n">weightInitOpt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weightStd</span> <span class="o">=</span> <span class="n">weightStd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zDim</span> <span class="o">=</span> <span class="n">zDim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activationFunc</span> <span class="o">=</span> <span class="n">activationFunc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoderStride</span> <span class="o">=</span> <span class="n">encoderStride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumfilters</span> <span class="o">=</span> <span class="n">encoderNumFilters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoderFiltersize</span> <span class="o">=</span> <span class="n">encoderFilterSize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activationFuncFinal</span> <span class="o">=</span> <span class="n">activationFuncFinal</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">net_config</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;inputSize&#39;</span><span class="p">,</span><span class="s1">&#39;zDim&#39;</span><span class="p">,</span><span class="s1">&#39;encoderNumfilters&#39;</span><span class="p">,</span><span class="s1">&#39;encoderFiltersize&#39;</span><span class="p">,</span><span class="s1">&#39;activationFunc&#39;</span><span class="p">,</span><span class="s1">&#39;tiedWeights&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;weightInitOpt&#39;</span><span class="p">,</span><span class="s1">&#39;weightStd&#39;</span><span class="p">,</span><span class="s1">&#39;skipConnect&#39;</span><span class="p">,</span><span class="s1">&#39;padding&#39;</span><span class="p">,</span><span class="s1">&#39;encoderStride&#39;</span><span class="p">,</span><span class="s1">&#39;activationFuncFinal&#39;</span><span class="p">]</span>
        <span class="c1"># loading config file overwrites input arguments</span>
        <span class="k">if</span> <span class="n">configFile</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">net_ops</span><span class="o">.</span><span class="n">load_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">configFile</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputSize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;value must be given for inputSize (not None)&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderFiltersize</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderNumfilters</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderStride</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;the length of encoderNumfilters, encoderFilterSize and encoderStride must be equal.&#39;</span><span class="p">)</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumfilters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoderNumFilters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoderFilterSize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderFiltersize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoderFilterSize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderFiltersize</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoderStride</span> <span class="o">=</span> <span class="n">encoderStride</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputSize</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_target</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputSize</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">{</span> <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">{</span> <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_ops</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modelsAddrs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tiedWeights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tiedWeights</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># pre-compute shape of data after each layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inputSize</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span> <span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">conv_output_shape</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span><span class="p">[</span><span class="n">layerNum</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderFilterSize</span><span class="p">[</span><span class="n">layerNum</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderStride</span><span class="p">[</span><span class="n">layerNum</span><span class="p">])</span> <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">zDim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span><span class="p">[</span><span class="n">layerNum</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span><span class="p">[</span><span class="n">layerNum</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoderDataShape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1">#--</span>

        <span class="c1"># encoder weights</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span> <span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encoder_w</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> \
                <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderFilterSize</span><span class="p">[</span><span class="n">layerNum</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span><span class="p">[</span><span class="n">layerNum</span><span class="p">],</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span><span class="p">[</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">]],</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encoder_w</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span><span class="p">[</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">zDim</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># decoder weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decoder_w</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span> <span class="o">+</span> <span class="mi">3</span><span class="p">)]</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">zDim</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">decoderDataShape</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderNumFilters</span> <span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>  <span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tiedWeights</span><span class="p">[</span><span class="n">layerNum</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decoder_w</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span> <span class="p">)</span> <span class="o">+</span> <span class="n">layerNum</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> \
                    <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">decoderFilterSize</span><span class="p">[</span><span class="n">layerNum</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderNumFilters</span><span class="p">[</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">decoderNumFilters</span><span class="p">[</span><span class="n">layerNum</span><span class="p">]],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">tiedWeights</span><span class="p">[</span><span class="n">layerNum</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decoder_w</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span> <span class="p">)</span><span class="o">+</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> \
                    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encoder_w</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span> <span class="o">-</span> <span class="n">layerNum</span><span class="p">)</span> <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;unknown tiedWeights value: </span><span class="si">%i</span><span class="s1">. &#39;</span>
                                 <span class="s1">&#39;Must be 0 or 1 for each layer (or None).&#39;</span> <span class="o">%</span> <span class="n">tiedWeights</span><span class="p">[</span><span class="n">layerNum</span><span class="p">])</span>


        <span class="c1"># encoder biases</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span> <span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;encoder_b</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> \
                <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span><span class="p">[</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span> <span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;encoder_b</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">zDim</span><span class="p">]</span> <span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># decoder biases</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;decoder_b</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span> <span class="o">+</span> <span class="mi">3</span><span class="p">)]</span> <span class="o">=</span> \
            <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">decoderDataShape</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderNumFilters</span> <span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>  <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;decoder_b</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span> <span class="p">)</span> <span class="o">+</span> <span class="n">layerNum</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> \
                <span class="n">net_ops</span><span class="o">.</span><span class="n">create_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">decoderNumFilters</span><span class="p">[</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">]],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weightInitOpt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># build network using encoder, decoder and x placeholder as input</span>

        <span class="c1"># build encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># expand to shape None x inputSize x 1</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="mi">1</span> <span class="p">,</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span> <span class="p">)</span> <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="p">)]</span> <span class="o">=</span> \
                <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_conv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encoder_w</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="p">)],</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;encoder_b</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="p">)],</span><span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderStride</span><span class="p">[</span><span class="n">layerNum</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="p">)]</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">activationFunc</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="p">)],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span><span class="p">[</span><span class="n">layerNum</span><span class="p">]]</span> <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> \
            <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_fullyConn</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="p">)],</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encoder_w</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;encoder_b</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">activationFunc</span><span class="p">)</span>


        <span class="c1"># latent representation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="c1"># collapse a dim</span>

        <span class="c1"># build decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> \
            <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_fullyConn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decoder_w</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">2</span><span class="p">)],</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;decoder_b</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">2</span><span class="p">)])</span>
        <span class="k">if</span> <span class="n">skipConnect</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">2</span><span class="p">)]</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderNumFilters</span> <span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span> <span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span><span class="p">[</span><span class="n">layerNum</span><span class="p">]]</span> <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">2</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">activationFunc</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layerNum</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoderDataShape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span><span class="bp">self</span><span class="o">.</span><span class="n">encoderNumFilters</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="p">)</span>
        <span class="k">for</span> <span class="n">layerNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="mi">1</span> <span class="p">,</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderNumFilters</span> <span class="p">)</span> <span class="p">):</span>
            <span class="n">absLayerNum</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoderDataShape</span> <span class="p">)</span> <span class="o">+</span> <span class="n">layerNum</span>
            <span class="n">outputShape</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
                           <span class="bp">self</span><span class="o">.</span><span class="n">decoderDataShape</span><span class="p">[</span><span class="n">layerNum</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">decoderNumFilters</span><span class="p">[</span><span class="n">layerNum</span><span class="p">]]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span> <span class="o">=</span> \
                <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_deconv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">absLayerNum</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decoder_w</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">absLayerNum</span><span class="p">)],</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;decoder_b</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">absLayerNum</span><span class="p">)],</span>
                                       <span class="n">outputShape</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">decoderStride</span><span class="p">[</span><span class="n">layerNum</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">layerNum</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderNumFilters</span> <span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">skipConnect</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoderNumFilters</span> <span class="p">)</span> <span class="o">-</span> <span class="n">layerNum</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">activationFunc</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">skipConnect</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a0&#39;</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">layer_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">activationFuncFinal</span><span class="p">)</span>

        <span class="c1"># output of final layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_recon</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;a</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">absLayerNum</span><span class="p">)]</span> <span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>



<div class="viewcode-block" id="cnn_1D_network.add_train_op"><a class="viewcode-back" href="../../usage/mods/mod_ae_cnn.html#deephyp.autoencoder.cnn_1D_network.add_train_op">[docs]</a>    <span class="k">def</span> <span class="nf">add_train_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="p">,</span><span class="n">lossFunc</span><span class="o">=</span><span class="s1">&#39;SSE&#39;</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">decay_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decay_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">piecewise_bounds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">piecewise_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span> <span class="n">wd_lambda</span><span class="o">=</span><span class="mf">0.0</span> <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Constructs a loss op and training op from a specific loss function and optimiser. User gives the ops a name, \</span>
<span class="sd">            and the train op and loss opp are stored in a dictionary (train_ops) under that name.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): Name of the training op (to refer to it later in-case of multiple training ops).</span>
<span class="sd">            lossFunc (str): Reconstruction loss function.</span>
<span class="sd">            learning_rate (float): Controls the degree to which the weights are updated during training.</span>
<span class="sd">            decay_steps (int): Epoch frequency at which to decay the learning rate.</span>
<span class="sd">            decay_rate (float): Fraction at which to decay the learning rate.</span>
<span class="sd">            piecewise_bounds (int list): Epoch step intervals for decaying the learning rate. Alternative to decay steps.</span>
<span class="sd">            piecewise_values (float list): Rate at which to decay the learning rate at the piecewise_bounds.</span>
<span class="sd">            method (str): Optimisation method.</span>
<span class="sd">            wd_lambda (float): Scalar to control weighting of weight decay in loss.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># construct loss op</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_ops</span><span class="p">[</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_loss&#39;</span><span class="o">%</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">loss_function_reconstruction_1D</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_recon</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_target</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span><span class="n">lossFunc</span><span class="p">)</span>

        <span class="c1"># weight decay loss contribution</span>
        <span class="n">wdLoss</span> <span class="o">=</span> <span class="n">net_ops</span><span class="o">.</span><span class="n">loss_weight_decay</span><span class="p">(</span><span class="n">wd_lambda</span><span class="p">)</span>

        <span class="c1"># construct training op</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_ops</span><span class="p">[</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_train&#39;</span><span class="o">%</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">net_ops</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_ops</span><span class="p">[</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_loss&#39;</span><span class="o">%</span><span class="n">name</span><span class="p">]</span><span class="o">+</span><span class="n">wdLoss</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">decay_steps</span><span class="p">,</span> <span class="n">decay_rate</span><span class="p">,</span> <span class="n">piecewise_bounds</span><span class="p">,</span> <span class="n">piecewise_values</span><span class="p">,</span><span class="n">method</span><span class="p">)</span></div>




<div class="viewcode-block" id="cnn_1D_network.train"><a class="viewcode-back" href="../../usage/mods/mod_ae_cnn.html#deephyp.autoencoder.cnn_1D_network.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataTrain</span><span class="p">,</span> <span class="n">dataVal</span><span class="p">,</span> <span class="n">train_op_name</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">save_addr</span><span class="p">,</span> <span class="n">visualiseRateTrain</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">visualiseRateVal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
              <span class="n">save_epochs</span><span class="o">=</span><span class="p">[</span><span class="mi">1000</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot; Calls network_ops function to train a network.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataTrain (obj): Iterator object for training data.</span>
<span class="sd">            dataVal (obj): Iterator object for validation data.</span>
<span class="sd">            train_op_name (str): Name of training op created.</span>
<span class="sd">            n_epochs (int): Number of loops through dataset to train for.</span>
<span class="sd">            save_addr (str): Address of a directory to save checkpoints for desired epochs, or address of saved \</span>
<span class="sd">                        checkpoint. If address is for an epoch and contains a previously saved checkpoint, then the \</span>
<span class="sd">                        network will start training from there. Otherwise it will be trained from scratch.</span>
<span class="sd">            visualiseRateTrain (int): Epoch rate at which to print training loss in console.</span>
<span class="sd">            visualiseRateVal (int): Epoch rate at which to print validation loss in console.</span>
<span class="sd">            save_epochs (int list): Epochs to save checkpoints at.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># make sure a checkpoint is saved at n_epochs</span>
        <span class="k">if</span> <span class="n">n_epochs</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">save_epochs</span><span class="p">:</span>
            <span class="n">save_epochs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>

        <span class="n">net_ops</span><span class="o">.</span><span class="n">train</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dataTrain</span><span class="p">,</span> <span class="n">dataVal</span><span class="p">,</span> <span class="n">train_op_name</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">save_addr</span><span class="p">,</span> <span class="n">visualiseRateTrain</span><span class="p">,</span> <span class="n">visualiseRateVal</span><span class="p">,</span> <span class="n">save_epochs</span> <span class="p">)</span></div>


<div class="viewcode-block" id="cnn_1D_network.add_model"><a class="viewcode-back" href="../../usage/mods/mod_ae_cnn.html#deephyp.autoencoder.cnn_1D_network.add_model">[docs]</a>    <span class="k">def</span> <span class="nf">add_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">addr</span><span class="p">,</span><span class="n">modelName</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Loads a saved set of model parameters for the network.</span>

<span class="sd">        Args:</span>
<span class="sd">            addr (str): Address of the directory containing the checkpoint files.</span>
<span class="sd">            modelName (str): Name of the model (to refer to it later in-case of multiple models for a given network).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">modelsAddrs</span><span class="p">[</span><span class="n">modelName</span><span class="p">]</span> <span class="o">=</span> <span class="n">addr</span></div>


<div class="viewcode-block" id="cnn_1D_network.encoder"><a class="viewcode-back" href="../../usage/mods/mod_ae_cnn.html#deephyp.autoencoder.cnn_1D_network.encoder">[docs]</a>    <span class="k">def</span> <span class="nf">encoder</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">modelName</span><span class="p">,</span> <span class="n">dataSamples</span>  <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Extract the latent variable of some dataSamples using a trained model.</span>

<span class="sd">        Args:</span>
<span class="sd">            modelName (str): Name of the model to use (previously added with add_model() ).</span>
<span class="sd">            dataSample (np.array): Shape [numSamples x inputSize].</span>

<span class="sd">        Returns:</span>
<span class="sd">            (np.array): Latent representation z of dataSamples. Shape [numSamples x arbitrary].</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

            <span class="c1"># load the model</span>
            <span class="n">net_ops</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modelsAddrs</span><span class="p">[</span><span class="n">modelName</span><span class="p">],</span> <span class="n">sess</span><span class="p">)</span>

            <span class="c1"># get latent values</span>
            <span class="n">dataZ</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">:</span> <span class="n">dataSamples</span><span class="p">})</span>

            <span class="k">return</span> <span class="n">dataZ</span></div>



<div class="viewcode-block" id="cnn_1D_network.decoder"><a class="viewcode-back" href="../../usage/mods/mod_ae_cnn.html#deephyp.autoencoder.cnn_1D_network.decoder">[docs]</a>    <span class="k">def</span> <span class="nf">decoder</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">modelName</span><span class="p">,</span> <span class="n">dataZ</span>  <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Extract the reconstruction of some dataSamples from their latent representation encoding  using a trained \</span>
<span class="sd">            model.</span>

<span class="sd">        Args:</span>
<span class="sd">            modelName (str): Name of the model to use (previously added with add_model() ).</span>
<span class="sd">            dataZ (np.array): Latent representation of data samples to reconstruct using the network. Shape \</span>
<span class="sd">                    [numSamples x arbitrary].</span>

<span class="sd">        Returns:</span>
<span class="sd">            (np.array): Reconstructed data (y_recon attribute). Shape [numSamples x arbitrary].</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

            <span class="c1"># load the model</span>
            <span class="n">net_ops</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modelsAddrs</span><span class="p">[</span><span class="n">modelName</span><span class="p">],</span> <span class="n">sess</span><span class="p">)</span>

            <span class="c1"># get reconstruction</span>
            <span class="n">dataY_recon</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_recon</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">:</span> <span class="n">dataZ</span><span class="p">})</span>

            <span class="k">return</span> <span class="n">dataY_recon</span></div>


<div class="viewcode-block" id="cnn_1D_network.encoder_decoder"><a class="viewcode-back" href="../../usage/mods/mod_ae_cnn.html#deephyp.autoencoder.cnn_1D_network.encoder_decoder">[docs]</a>    <span class="k">def</span> <span class="nf">encoder_decoder</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">modelName</span><span class="p">,</span> <span class="n">dataSamples</span>  <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Extract the reconstruction of some dataSamples using a trained model.</span>

<span class="sd">        Args:</span>
<span class="sd">            modelName (str): Name of the model to use (previously added with add_model() ).</span>
<span class="sd">            dataSample (np.array): Data samples to reconstruct using the network. Shape [numSamples x inputSize].</span>

<span class="sd">        Returns:</span>
<span class="sd">            (np.array): Reconstructed data (y_recon attribute). Shape [numSamples x arbitrary].</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

            <span class="c1"># load the model</span>
            <span class="n">net_ops</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modelsAddrs</span><span class="p">[</span><span class="n">modelName</span><span class="p">],</span> <span class="n">sess</span><span class="p">)</span>

            <span class="c1"># get reconstruction</span>
            <span class="n">dataY_recon</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_recon</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">:</span> <span class="n">dataSamples</span><span class="p">})</span>

            <span class="k">return</span> <span class="n">dataY_recon</span></div></div>







</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Lloyd Windrim

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>